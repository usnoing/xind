import requests
import json
import time
import csv
from urllib.parse import urljoin
from datetime import datetime

class LinuxDoAPIClient:
    def __init__(self, base_url="https://linux.do"):
        self.base_url = base_url
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'ResearchBot/1.0 (+https://example.com/research)',
            'Accept': 'application/json',
            'Content-Type': 'application/json'
        })
        
    def get_site_info(self):
        """è·å–ç½‘ç«™åŸºæœ¬ä¿¡æ¯"""
        try:
            response = self.session.get(
                urljoin(self.base_url, '/site.json'),
                timeout=10
            )
            if response.status_code == 200:
                return response.json()
            else:
                print(f"è·å–site.jsonå¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                return None
        except Exception as e:
            print(f"è·å–ç½‘ç«™ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    def explore_available_apis(self):
        """æ¢ç´¢å¯ç”¨çš„APIç«¯ç‚¹"""
        print("æ¢ç´¢å¯ç”¨çš„APIç«¯ç‚¹...")
        
        # Discourseå¸¸è§çš„APIç«¯ç‚¹
        api_endpoints = [
            '/categories.json',
            '/latest.json',           # æœ€æ–°å¸–å­
            '/top.json',              # çƒ­é—¨å¸–å­
            '/posts.json',            # å¸–å­
            '/users.json',            # ç”¨æˆ·
            '/tags.json',             # æ ‡ç­¾
            '/about.json',            # å…³äºé¡µé¢
            '/search.json',           # æœç´¢
        ]
        
        available_apis = []
        
        for endpoint in api_endpoints:
            try:
                time.sleep(1)  # è¯·æ±‚é—´éš”
                response = self.session.get(
                    urljoin(self.base_url, endpoint),
                    timeout=10
                )
                
                if response.status_code == 200:
                    print(f"âœ… {endpoint}: å¯ç”¨")
                    available_apis.append(endpoint)
                else:
                    print(f"âŒ {endpoint}: ä¸å¯ç”¨ ({response.status_code})")
                    
            except Exception as e:
                print(f"âŒ {endpoint}: é”™è¯¯ - {e}")
        
        return available_apis
    
    def get_categories(self):
        """è·å–åˆ†ç±»ä¿¡æ¯"""
        try:
            response = self.session.get(
                urljoin(self.base_url, '/categories.json'),
                timeout=10
            )
            if response.status_code == 200:
                return response.json().get('category_list', {}).get('categories', [])
            return []
        except Exception as e:
            print(f"è·å–åˆ†ç±»å¤±è´¥: {e}")
            return []
    
    def get_latest_topics(self, page=0):
        """è·å–æœ€æ–°è¯é¢˜"""
        try:
            params = {'page': page}
            response = self.session.get(
                urljoin(self.base_url, '/latest.json'),
                params=params,
                timeout=10
            )
            if response.status_code == 200:
                return response.json().get('topic_list', {}).get('topics', [])
            return []
        except Exception as e:
            print(f"è·å–æœ€æ–°è¯é¢˜å¤±è´¥: {e}")
            return []
    
    def get_top_topics(self, period='daily'):
        """è·å–çƒ­é—¨è¯é¢˜"""
        try:
            params = {'period': period}
            response = self.session.get(
                urljoin(self.base_url, '/top.json'),
                params=params,
                timeout=10
            )
            if response.status_code == 200:
                return response.json().get('topic_list', {}).get('topics', [])
            return []
        except Exception as e:
            print(f"è·å–çƒ­é—¨è¯é¢˜å¤±è´¥: {e}")
            return []
    
    def get_topic_posts(self, topic_id):
        """è·å–ç‰¹å®šè¯é¢˜çš„å¸–å­"""
        try:
            response = self.session.get(
                urljoin(self.base_url, f'/t/{topic_id}.json'),
                timeout=10
            )
            if response.status_code == 200:
                return response.json()
            return None
        except Exception as e:
            print(f"è·å–è¯é¢˜ {topic_id} çš„å¸–å­å¤±è´¥: {e}")
            return None
    
    def search_topics(self, query, page=0):
        """æœç´¢è¯é¢˜"""
        try:
            params = {
                'q': query,
                'page': page
            }
            response = self.session.get(
                urljoin(self.base_url, '/search.json'),
                params=params,
                timeout=10
            )
            if response.status_code == 200:
                return response.json()
            return None
        except Exception as e:
            print(f"æœç´¢è¯é¢˜å¤±è´¥: {e}")
            return None

class DataProcessor:
    """æ•°æ®å¤„ç†ç±»"""
    
    @staticmethod
    def process_site_info(site_data):
        """å¤„ç†ç½‘ç«™ä¿¡æ¯"""
        if not site_data:
            return None
            
        processed = {
            'title': site_data.get('title'),
            'description': site_data.get('description'),
            'topics_count': site_data.get('topics_count'),
            'posts_count': site_data.get('posts_count'),
            'users_count': site_data.get('users_count'),
            'categories_count': site_data.get('categories_count'),
            'created_at': site_data.get('created_at'),
            'updated_at': datetime.now().isoformat()
        }
        return processed
    
    @staticmethod
    def process_topics(topics):
        """å¤„ç†è¯é¢˜åˆ—è¡¨"""
        processed_topics = []
        for topic in topics:
            processed = {
                'id': topic.get('id'),
                'title': topic.get('title'),
                'slug': topic.get('slug'),
                'posts_count': topic.get('posts_count'),
                'reply_count': topic.get('reply_count'),
                'views': topic.get('views'),
                'like_count': topic.get('like_count'),
                'created_at': topic.get('created_at'),
                'last_posted_at': topic.get('last_posted_at'),
                'visible': topic.get('visible'),
                'closed': topic.get('closed'),
                'archived': topic.get('archived'),
                'category_id': topic.get('category_id')
            }
            processed_topics.append(processed)
        return processed_topics
    
    @staticmethod
    def save_to_json(data, filename):
        """ä¿å­˜æ•°æ®åˆ°JSONæ–‡ä»¶"""
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            print(f"âœ… æ•°æ®å·²ä¿å­˜åˆ° {filename}")
        except Exception as e:
            print(f"âŒ ä¿å­˜æ•°æ®å¤±è´¥: {e}")
    
    @staticmethod
    def save_topics_to_csv(topics, filename):
        """ä¿å­˜è¯é¢˜æ•°æ®åˆ°CSV"""
        if not topics:
            print("âŒ æ²¡æœ‰æ•°æ®å¯ä¿å­˜")
            return
            
        try:
            with open(filename, 'w', newline='', encoding='utf-8') as f:
                fieldnames = ['id', 'title', 'posts_count', 'views', 'like_count', 'created_at']
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                
                for topic in topics:
                    writer.writerow({
                        'id': topic.get('id'),
                        'title': topic.get('title'),
                        'posts_count': topic.get('posts_count'),
                        'views': topic.get('views'),
                        'like_count': topic.get('like_count'),
                        'created_at': topic.get('created_at')
                    })
            print(f"âœ… è¯é¢˜æ•°æ®å·²ä¿å­˜åˆ° {filename}")
        except Exception as e:
            print(f"âŒ ä¿å­˜CSVå¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("Linux.do Discourse API æ•°æ®æ”¶é›†å·¥å…·")
    print("=" * 60)
    
    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = LinuxDoAPIClient()
    processor = DataProcessor()
    
    # 1. è·å–ç½‘ç«™åŸºæœ¬ä¿¡æ¯
    print("\n1. è·å–ç½‘ç«™åŸºæœ¬ä¿¡æ¯...")
    site_info = client.get_site_info()
    if site_info:
        processed_site = processor.process_site_info(site_info)
        processor.save_to_json(processed_site, 'linux_do_site_info.json')
        print(f"   - ç½‘ç«™æ ‡é¢˜: {processed_site.get('title')}")
        print(f"   - è¯é¢˜æ•°é‡: {processed_site.get('topics_count')}")
        print(f"   - å¸–å­æ•°é‡: {processed_site.get('posts_count')}")
        print(f"   - ç”¨æˆ·æ•°é‡: {processed_site.get('users_count')}")
    else:
        print("âŒ æ— æ³•è·å–ç½‘ç«™ä¿¡æ¯")
        return
    
    # 2. æ¢ç´¢å¯ç”¨API
    print("\n2. æ¢ç´¢å¯ç”¨APIç«¯ç‚¹...")
    available_apis = client.explore_available_apis()
    print(f"   å‘ç° {len(available_apis)} ä¸ªå¯ç”¨APIç«¯ç‚¹")
    
    # 3. è·å–åˆ†ç±»ä¿¡æ¯
    print("\n3. è·å–åˆ†ç±»ä¿¡æ¯...")
    categories = client.get_categories()
    if categories:
        processor.save_to_json(categories, 'linux_do_categories.json')
        print(f"   å‘ç° {len(categories)} ä¸ªåˆ†ç±»")
        for category in categories[:5]:  # æ˜¾ç¤ºå‰5ä¸ªåˆ†ç±»
            print(f"   - {category.get('name')} (ID: {category.get('id')})")
    
    # 4. è·å–æœ€æ–°è¯é¢˜
    print("\n4. è·å–æœ€æ–°è¯é¢˜...")
    latest_topics = client.get_latest_topics()
    if latest_topics:
        processed_topics = processor.process_topics(latest_topics)
        processor.save_to_json(processed_topics, 'linux_do_latest_topics.json')
        processor.save_topics_to_csv(processed_topics, 'linux_do_latest_topics.csv')
        print(f"   è·å–åˆ° {len(latest_topics)} ä¸ªæœ€æ–°è¯é¢˜")
        
        # æ˜¾ç¤ºå‰5ä¸ªè¯é¢˜
        for topic in processed_topics[:5]:
            print(f"   - {topic.get('title')} (æµè§ˆ: {topic.get('views')})")
    
    # 5. è·å–çƒ­é—¨è¯é¢˜
    print("\n5. è·å–çƒ­é—¨è¯é¢˜...")
    top_topics = client.get_top_topics('daily')
    if top_topics:
        processed_top = processor.process_topics(top_topics)
        processor.save_to_json(processed_top, 'linux_do_top_topics.json')
        print(f"   è·å–åˆ° {len(top_topics)} ä¸ªçƒ­é—¨è¯é¢˜")
    
    # 6. æœç´¢ç¤ºä¾‹
    print("\n6. æœç´¢Linuxç›¸å…³è¯é¢˜...")
    search_results = client.search_topics('linux')
    if search_results:
        processor.save_to_json(search_results, 'linux_do_search_results.json')
        print(f"   æœç´¢åˆ° {search_results.get('posts', [])} ä¸ªç›¸å…³å¸–å­")
    
    print("\n" + "=" * 60)
    print("æ•°æ®æ”¶é›†å®Œæˆ!")
    print("=" * 60)
    print("ç”Ÿæˆçš„æ–‡ä»¶:")
    print("âœ… linux_do_site_info.json - ç½‘ç«™åŸºæœ¬ä¿¡æ¯")
    print("âœ… linux_do_categories.json - åˆ†ç±»ä¿¡æ¯") 
    print("âœ… linux_do_latest_topics.json - æœ€æ–°è¯é¢˜")
    print("âœ… linux_do_latest_topics.csv - æœ€æ–°è¯é¢˜(CSVæ ¼å¼)")
    print("âœ… linux_do_top_topics.json - çƒ­é—¨è¯é¢˜")
    print("âœ… linux_do_search_results.json - æœç´¢ç»“æœ")
    
    print("\nä½¿ç”¨è¯´æ˜:")
    print("ğŸ“Š æ‰€æœ‰æ•°æ®ä»…å¯ç”¨äºæ„å»ºæœç´¢ç´¢å¼•")
    print("ğŸš« ç¦æ­¢ç”¨äºAIæ¨¡å‹è®­ç»ƒ")
    print("âš–ï¸ éµå®ˆå†…å®¹ä¿¡å·: search=yes, ai-train=no")
    print("ğŸ¤ å°Šé‡APIä½¿ç”¨é™åˆ¶")

if __name__ == "__main__":
    main()